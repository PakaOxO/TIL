
>[!tip] 서론
>
>&nbsp;&nbsp;개발자 인터뷰에서 자주 등장하는 CS 질문들을 정리하고, 복습하기 위한 노트입니다. 학습한 내용을 배경으로 면접을 준비하는 과정에서 작성된 노트인만큼 정확하지 않는 정보가 포함되어 있을 수 있습니다.

<br>

### 운영체제(OS)란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;운영체제는 실행할 프로그램에 필요한 자원을 할당하고, 프로그램이 올바르게 실행되도록 돕는 특별한 프로그램입니다. 운영체제는 컴퓨터 부팅 시에 메모리 내 `커널 영역(kernel space)`라는 별도의 공간에 따로 적재되어 실행됩니다.
</details>

<br>

### 커널(Kernel)영역이란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;메모리는 크게 커널 영역과 사용자 영역으로 구분됩니다. 그 중에서 커널 영역은 운영체제에서 필요한 핵심 부분만을 메인 메모리에 적재하여 운영체제를 사용하기 위한 메모리 영역입니다. 메모리의 커널영역을 차지하는 커널은 운영체제의 핵심 서비스로 자원에 접근하고 조작하는 기능, 프로그램이 안전하게 실행되게 하는 기능 등이 포함되어 있는 인터페이스입니다.
</details>

<br>

### 메모리의 구조

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;메모리는 크게 커널 영역과 사용자 영역으로 구분되어 있습니다. 그 중 사용자 영역은 다시 코드, 데이터, 힙, 스택 영역으로 나뉩니다.
<br>
  &nbsp;&nbsp;`코드 영역`은 실행할 수 있는 코드인 기계어로 이루어진 명령어가 저장되는 영역입니다. CPU가 실행할 명령어가 담겨 있기 때문에 쓰기가 금지되어 있는 `읽기 전용(read-only)` 공간입니다. 코드 영역은 텍스트 영역(text segment)라고도 부릅니다.
<br>
  &nbsp;&nbsp;`데이터 영역`은 프로그램이 실행되는 동안 유지할 데이터가 할당되는 공간입니다. 대표적으로 `전역 변수(global variable)` 등이 저장됩니다.
<br>
  &nbsp;&nbsp;`힙 영역`은 프로그래머가 직접 할당할 수 있는 저장 공간으로 객체 등이 동적으로 메모리에 할당, 해제됩니다. 메모리 공간의 힙 영역에 어떠한 데이터를 할당 했다면 이를 운영체제에 반환하는 과정도 필요합니다. 만약 메모리 공간이 반환되지 않는다면 메모리의 낭비 현상인 `메모리 누수(memory leak)`가 발생할 수 있습니다. 힙 영역은 스택 영역과 겹치는 것을 방지하기 위해 메모리의 낮은 주소에서 높은 주소로 할당됩니다.
<br>
  &nbsp;&nbsp;`스택 영역`은 정적 할당 영역인 데이터 영역과 달리 데이터가 일시적으로 저장되는 공간입니다. 대표적으로 `매개 변수`, `지역 변수` 등이 저장됩니다. 힙 영역과 겹치는 것을 방지하기 위해 메모리 주소가 높은 주소에서 낮은 주소로 할당됩니다.
</details>

<br>

### 메모리 힙 영역과 스택 영역의 차이점?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;우선 메모리를 차지하는 영역의 크기는 힙 영역의 경우 런타임 타임에, 스택 영역의 경우 컴파일 타임에 결정됩니다. 각 영역의 저장되는 데이터는 힙 영역은 생성자 등에 의해 동적으로 생성된 객체이며, 스택 영역은 지역 변수 또는 매개 변수 등이 있습니다. 힙 영역은 낮은 주소에서 높은 주소로, 스택 영역은 높은 주소에서 낮은 영역으로 순차적으로 할당이 이루어지는데, 서로의 영역을 누가 침범하느냐에 따라 `힙 오버플로우` 또는 `스택 오버플로우`가 발생할 수 있습니다.
</details>

<br>

### 프로세스와 스레드의 차이점?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`프로세스`는 메인 메모리에 적재되어 실행되는 프로그램입니다. 하나의 프로세스가 생성되면 메모리의 커널 영역에는 PCB가 사용자 영역에는 코드, 데이터, 힙, 스택 영역으로 구분되어 저장됩니다. 각각의 프로세스는 별개의 메모리 영역을 차지하기 때문에 동기화 작업이 필요하지 않습니다. 다만 CPU의 자원을 사용하기 위해서는 프로세스 사이의 작업 전환을 위해 `문맥 교환(Context Switching)`이 필요합니다.
<br>
  &nbsp;&nbsp;`스레드`는 프로세스의 실행 흐름, 또는 실행 단위를 가리킵니다. 하나의 프로세스가 가진 메모리 영역에서 `스택` 영역만 별개로 할당 받고, 나머지 영역은 공유합니다. 이로 인해 공유하는 자원에 대한 동기화 작업이 필요할 수 있습니다. 또한 자원을 공유함으로써 하나의 스레드에 문제가 발생한다면 다른 스레드에 영향을 줄 수 있습니다.
</details>

<br>

### 문맥 교환이란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`문맥 교환(Context Switching)`은 CPU가 여러 프로세스를 처리하기 위한 기법입니다. I/O 작업의 경우 CPU의 처리 속도에 비해 아주 느립니다. 만약 이런 상황의 경우 I/O의 작업을 기다리는 것보다 잠시 다른 작업을 처리하는 것이 더욱 효율적일 수 있으며, CPU의 자원을 사용하던 Task(프로세스 혹은 스레드)가 다른 Task에게 자원을 넘겨주기 위해 자신의 처리 상태(문맥)를 자신의 PCB에 백업하고, 새로 작업할 Task의 PCB에서 이전의 처리 상태를 읽어 레지스터에 적재하는 과정이 바로 `문맥 교환`입니다.
</details>

<br>

### PCB란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`PCB(Process Control Block)`는 프로세스 제어 블록으로 프로세스가 실행되면 OS에 의해 커널 영역에 생성되는 자료구조입니다. PCB는 프로세스에 대한 정보를 담고 있으며, 대표적으로 프로세스 식별자(PID), 프로세스 상태(New / Ready / Running / Waiting / Terminated), 프로세스의 다음으로 명령어가 실행될 주소인 프로그램 카운터 등이 포함되어 있습니다.OS는 기존의 Task에서 다른 Task로 작업을 전환하기 위해 PCB에 담긴 정보를 활용해 `문맥 교환`을 실시합니다.
</details>

<br>

### 멀티 프로세스와 멀티 스레드의 차이점?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;하나의 프로그램을 멀티 프로세스로 실행했을 경우, 각 프로세스가 독립적인 메모리를 할당받아 사용하기 때문에 문맥 교환을 위해 초기화되는 영역이 멀티 스레드에 비해 크기 때문에 문맥 교환을 위한 비용이 크며, 많은 메모리 공간을 차지하게 됩니다. 하지만 독립적인 메모리 공간을 사용하는 만큼 하나의 프로세스가 죽더라도 다른 프로세스에는 영향을 주지 않습니다.
<br>
  &nbsp;&nbsp;멀티 스레드는 하나의 프로세스에서 스택 이외의 메모리 공간을 공유하는 만큼 문맥 교환을 위한 비용이 적습니다. 다만 메모리를 공유하는 만큼 오류가 발생하면 다른 스레드에 영향을 줄 수 있다는 안정성 문제가 있습니다. 공유 자원으로 인한 문제를 방지하기 위해 `동기화` 작업이 필요합니다. 동기화 작업은 공유 자원에 접근하는 스레드의 수를 제한하므로 병목현상으로 인한 성능 저하가 발생할 수 있습니다. 추가로, 스레드는 독립적인 스택 영역을 할당받음으로써 독립적인 함수 호출이 가능해져 프로세스 내에서 독립적인 실행흐름을 가질 수 있게 됩니다.
</details>

<br>

### 멀티 프로세스와 멀티 스레드의 예

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;멀티 프로세스의 대표적인 예시로는 브라우저의 멀티 창, 혹은 멀티 탭이 있습니다. 각각의 탭은 서로 독립적인 페이지에 대한 작업을 수행하므로 별개의 프로세스로서 실행되어야 합니다. 각각의 탭은 별개의 프로세스로서 동작하지만 부모 프로세스(브라우저)로부터 생성된 자식 프로세스로 브라우저 설정 등 일부 공유할 수 있는 자원을 가질 수 있습니다.
<br>
  &nbsp;&nbsp;멀티 스레드의 경우, 단일 탭에서 I/O, 비동기 처리, 이벤트 루프 등의 작업을 서로 별개의 흐름으로 동시에 처리하기 위해 사용됩니다.
</details>

<br>

### 동시성과 병렬성의 차이점?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`동시성`은 멀티 프로그래밍으로부터 시작된 개념으로 주 기억장치(RAM)에 여러 프로세스를 적재한 뒤, 문맥 교환을 통해 동시에 여러 프로세스가 실행되는 것처럼 보이게 하는 특징입니다. 실제로는 여러 작업이 문맥 교환에 의해 번갈아가며 실행되며 싱글 코어 환경에서 멀티 스레드를 실행하기 위해 사용됩니다.
  <br>
  &nbsp;&nbsp;반면 `병렬성`은 멀티 프로세싱으로부터 나온 개념으로 실제로 여러 프로세스를 동시에 실행하는 방식입니다. 동시 실행을 위해서는 멀티 코어 환경이 갖추어져야 합니다.
</details>

<br>

### 경쟁상태와 임계영역

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;두 개 이상의 스레드가 동일한 공유자원에 접근하기 위해 서로 경쟁하는 것을 `경쟁 상태(Race Condition)`이라고 합니다. 이러한 공유 자원이 존재하는 영역이 `임계 영역(Critical Section)`입니다. 임계 영역에 대한 경쟁 상태를 제거하기 위해서 공유 자원에 대해서 하나의 스레드만 접근할 수 있도록 `상호 배제` 기법을 사용할 수 있습니다.
</details>

<br>

### 뮤텍스와 세마포어 특징?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`뮤텍스(Mutex)`와 `세마포어(Semaphore)`는 모두 임계영역 자체에 락(Lock)을 거는 동기화 기법입니다. 락이 걸린 임계영역에는 다른 스레드가 접근할 수 없습니다.
  <br>
  &nbsp;&nbsp;뮤텍스는 임계영역에 접근할 수 있는 스레드의 수를 하나로 제한하기 위해 락으로 true/false의 이진 데이터를 사용하는 동기화 기법입니다. 임계영역에 락이 걸려있지 않다면 스레드는 임계영역의 자원을 사용하기 전 해당 임계영역에 락을 걸고, 작업이 완료되면 이를 해제(Release)하는 방식으로 동작합니다.
  <br>
  &nbsp;&nbsp;세마포어는 임계영역에 대한 락으로 양의 정수값을 사용합니다. 어떤 임계영역에 대한 락이 1 이상이라면 새로 작업을 시작하는 스레드는 값을 1만큼 감소시키고, 작업을 시작합니다. 락으로 0과 1의 이진 데이터를 사용하는 이진 세마포어는 뮤텍스와 동일하게 동작합니다.
  <br>
  &nbsp;&nbsp;뮤텍스와 세마포어는 임계영역에 락이 걸려있는지 확인하기 위해 지속적으로 확인하는 `busy wait` 방식을 사용합니다. 하지만 세마포어의 경우 준비 큐를 사용해 불필요하게 락을 체크하지 않는 방법도 사용할 수 있습니다. 준비 큐에는 락에 의해 실행되지 못한 Task가 sleep 상태로 담겨있고, 작업이 끝난 Task는 준비 큐의 가장 첫 번째 Task를 꺼내 깨우는 awake를 호출합니다.
</details>

<br>

### 교착상태란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`교착상태(DeadLock)`는 두 개 이상의 프로세스 또는 스레드가 서로 자원을 기다리면서 발생하는 무한히 대기하고 있는 현상입니다. 교착상태가 발생하기 위해서는 `상호배제`, `점유 대기`, `비선점`, `순환대기`의 4가지 요소가 모두 충족되어야 합니다. 이 중 하나라도 제거 되었을 경우 교착상태는 해소될 수 있습니다.
</details>

<br>

### CPU 스케줄링이란? 그리고 종류는?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;모든 프로세스는 CPU 자원을 필요로 하기 때문에 각 프로세스가 CPU를 사용할 순서를 정하기 위해 `CPU 스케줄링`을 통해 합리적으로 CPU 자원을 배분합니다.
  <br>
  &nbsp;&nbsp;CPU 스케줄링의 종류로는 대표적으로 `선입선처리(FCFS, First-come First-served)`, `최단작업(SJF, Shortest job first)`, `라운드로빈(Round-Robin)`, `다단계 피드백 큐` 스케줄링이 있습니다.
</details>

<br>

### CPU 스케줄링 종류별 설명

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`선입선처리(FCFS, First-come First-served)` 스케줄링은 먼저 준비 큐에 삽입된 프로세스를 우선적으로 처리하는 알고리즘입니다. 만약 아주 긴 프로세스가 먼저 삽입되었다면 이를 위해 다른 짧은 프로세스들이 오랜 시간 대기하게 되는 `호위 효과(Convoy Effect)`가 발생할 수 있습니다.
  <br>
  &nbsp;&nbsp;`최단작업(SJF, Shortest job first)` 스케줄링은 가장 CPU 사용시간이 짧은 프로세스를 우선적으로 실행하는 알고리즘입니다. 호위효과를 방지할 수 있으며, 비선점형 스케줄링으로 분류됩니다.(선점형 최단작업 스케줄링도 있긴 합니다).
  <br>
  &nbsp;&nbsp;`라운드로빈(Round-Robin)` 스케줄링은 `선입선처리` 스케줄링에 CPU를 사용할 수 있는 시간인 `타임 슬라이스`가 도입된 개념으로 선점형 스케줄링입니다. 각각의 프로세스는 타임 슬라이스만큼 CPU를 사용할 수 있으며, 주어진 시간 내에 작업을 완료하지 못했다면 다시 준비 큐 맨 뒤에 삽입됩니다.
  <br>
  &nbsp;&nbsp;`다단계 피드백 큐` 스케줄링은 `다단계 큐` 스케줄링을 확장한 알고리즘입니다. 우선 순위별로 구분된 단계별 큐에 프로세스를 삽입하는 다단계 큐 스케줄링의 경우 높은 우선순위를 가진 프로세스에 의해 낮은 우선순위의 프로세스가 계속해서 밀리는 `기아 현상`이 발생할 수 있습니다. 실행시간이 긴 프로세스의 경우 지정된 타임 슬라이스 내에 작업을 완료하지 못했다면 낮은 우선순위의 큐로 밀리고, 낮은 우선순위 큐에 있던 프로세스는 `에이징` 기법을 통해 높은 우선순위 큐로 이동시켜 기아 현상을 방지할 수 있습니다.
</details>

<br>

### 선점형 스케줄링과, 비선점형 스케줄링이란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`선점형 스케줄링`은 프로세스가 CPU를 비롯한 자원을 사용하고 있더라도 운영체제가 해당 프로세스로부터 자원을 빼앗아 다른 프로세스에 할당할 수 있는 스케줄링 방식입니다. 급한 프로세스가 언제든 끼어들 수 있어 자원 독점을 막을 수 있다는 장점이 있지만, 문맥 교환이 자주 발생할 수 있는 만큼 문맥 교환 과정에서 오버헤드가 발생할 수 있습니다.
  <br>
  &nbsp;&nbsp;반면 `비선점형 스케줄링`은 하나의 프로세스가 자원을 사용하고 있다면 그 프로세스가 종료되거나 스스로 대기 상태에 접어들기 전까진 다른 프로세스가 끼어들 수 없는 스케줄링 방식입니다. 문맥 교환의 빈도가 적어 오버헤드가 적게 발생지만 급한 프로세스가 있더라도 자원을 사용 중인 프로세스가 끝날 때까지 대기해야하므로 자원 활용 측면에선 비효율적일 수 있습니다.
</details>

<br>

### 인터럽트란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`인터럽트(Interrupt)`는 CPU가 명령어를 실행하는 도중 입출력 혹은 예외 상황을 처리하기 위해 실행하던 프로그램을 중간에 중단하고 바로 작업해야할 내용을 처리하도록 하는 것을 의미합니다.
</details>

<br>

### 시스템 콜이란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`시스템 콜(System Call)`은 운영체제의 서비스를 이용할 수 있도록 `커널 모드`로 전환하기 위한 인터페이스입니다. 시스템 콜을 통해서만 커널에 접근할 수 있으므로 컴퓨터 자원을 보호할 수 있으며, 사용자나 응용 프로그램은 시스템 콜을 통해 운영체제의 서비스를 제공받습니다.
</details>

<br>

### 메모리의 종류?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;컴퓨터의 메모리는 CPU에 가까운 순서로 계층화되어 있습니다. 메모리는 CPU에 가까운 순서로 `레지스터`, `캐시`, `주기억장치`, `보조기억장치`로 구분되며 CPU에서 멀어질 수록 접근속도가 느립니다.
  &nbsp;&nbsp;
</details>

<br>

### 캐시 메모리?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;CPU가 메모리에 접근하는 속도는 레지스터보다 느리지만 용량의 한계로 메모리에 접근하는 빈도는 높습니다. 이러한 문제를 해결하기 위한 것이 `캐시(Cache) 메모리`로 캐시 메모리는 `참조 지역성`의 성질을 가집니다. 캐시 메모리는 메모리보다 가까이 위치해있기 때문에 접근 속도가 빠르며, L1~L3로 계층화 되어있습니다. CPU에 가까운 계층일 수록 빠르지만, 용량이 작고 가격이 비싸집니다. 멀티 코어 프로세서에서 L1캐시와 L2캐시는 각 코어에 고유한 캐시 메모리로 할당됩니다. 반면 L3캐시는 모든 코어가 공유하는 형태로 사용됩니다.
  <br>
  &nbsp;&nbsp;`공간 지역성`은 현재 실행하는 프로그램과 관련된 명령어나 데이터는 메모리 상에서 비슷한 위치에 저장된다는 특성을 이용하는 것입니다. 현재 사용하는 메모리와 인접한 메모리의 데이터를 캐시에 저장하면 캐시 히트율을 높일 수 있습니다.
  <br>
  &nbsp;&nbsp;`시간 지역성`은 자주 사용하는 데이터는 이후에도 자주 접근하게 될 수 있다는 성질을 이용하는 것입니다. 자주 사용될 것으로 예상되는 데이터를 캐시에 저장하면 캐시 히트율을 높일 수 있습니다.
</details>

<br>

### 메모리 할당의 종류(Memory Fit)

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`First fit`은 메모리를 처음부터 검사한 뒤 처음으로 크기가 충분한 영역에 할당하는 방식입니다. `Next fit`은 마지막으로 참조한 메모리 영역 다음부터 검사를 시작해 크기가 충분한 영역에 할당합니다. `Best fit`은 모든 메모리 영역을 검사한 뒤 메모리에 할당할 수 있는 공간 중 가장 작은 영역에 할당하는 방식입니다. Worst fit`은 남은 메모리 영역 중 가장 큰 영역에 할당하는 방식입니다.
</details>

<br>

### 외부 단편화와 내부 단편화?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`외부 단편화(External gragmentation)`는 메모리 연속 할당 방식에 의해 발생하는 문제입니다. 실제 남은 메모리에 크기에 비해 단편화된 영역의 크기가 작아 메모리에 프로세스를 할당없는 것처럼 보여지는 메모리 낭비 현상입니다.
  <br>
  &nbsp;&nbsp;`내부 단편화(Internal gragmentation)`는 페이징 기법 및 메모리 고정길이 할당에서 발생하는 문제입니다. 페이징에 의해 페이지와 동일한 크기로 잘린 메모리 영역인 프레임에 페이지를 할당하는데, 실제 할당되는 페이지가 프레임보다 작아 발생하는 메모리 낭비입니다. (13MB인 프로세스를 4MB로 페이징 처리하면 마지막 프레임에는 1MB만 할당되어 3MB의 메모리 낭비가 발생)
</details>

<br>

### 페이징과 세그멘테이션

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`페이징`과 `세그멘테이션`은 모두 `가상 메모리`를 활용한 메모리 관리 기법입니다. 물리적인 메모리를 논리적인 구조로 변환하기 위해 테이블이 필요하며, 각각의 기법에 따라 `페이지 테이블`, `세그먼트 테이블`로 부릅니다.
  <br>
  &nbsp;&nbsp;`페이징`은 할당할 수 있는 영역을 프로세스의 데이터를 쪼개 담을 수 있는 `프레임`으로 나눈 뒤, 각각의 프레임에 페이지를 할당하는 기법입니다. 페이징을 활용하면 메모리 연속할당에 의해 발생할 수 있는 `외부 단편화`를 방지할 수 있습니다. 또한 모든 프로세스 데이터를 메모리에 적재하는 것이 아니라 일부 사용되는 페이지만 메모리에 적재하는 방식으로 실제 물리 메모리 용량보다 큰 프로세스를 실행하는 것이 가능해집니다.
  <br>
  &nbsp;&nbsp;페이징이 동일한 크기로 쪼개진 프레임에 페이지를 할당했다면, `세그멘테이션`은 가변적으로 쪼개진 세그먼트에 프로세스를 쪼개 할당하는 방식입니다. 대표적인 방법으로 프로세스의 논리적인 단위인 Code, Data, Heap, Stack 별로 세그먼트를 분리하는 것이 있습니다.
</details>

<br>

### 가상 메모리란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`가상 메모리`를 활용하면 모든 프로세스를 메모리에 적재하지 않아도 프로그램을 실행할 수 있습니다. `페이징` 기법 등을 활용하면 물리적인 메모리를 논리적인 단위로 쪼개 프로세스를 불연속적으로 할당할 수 있습니다. 이를 통해 `외부 단편화` 문제를 해결할 수 있으며, 메모리 용량보다 큰 프로세스를 실행하는 것 역시 가능하고, 한번에 여러 프로세스를 메모리에 할당할 수 있게 되므로 `멀티 프로그래밍`이 가능해집니다.
</details>

<br>

### 요구 페이징이란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`요구 페이징(Demand paging)`은 프로세스를 메모리에 적재할 때 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법입니다. 요구 페이징을 위해서는 페이지로 꽉찬 메모리를 새로 적재할 페이지로 교체하는 `페이지 교체`와 각 프로세스 별로 한정된 메모리에서 얼마만큼의 프레임을 할당받을 것인지에 대한 `프레임 할당` 문제를 해결해야 합니다.
  <br>
  &nbsp;&nbsp;페이지 교체의 경우 만약 지금 CPU가 실행하려는 명령어가 담긴 페이지가 메모리에 적재되어 있지 않다면 `페이지 폴트`가 발생하고, `페이지 교체 알고리즘`에 의해 적재된 페이지 중 일부를 `페이지 아웃`한 뒤 필요한 페이지를 메모리에 할당(페이지 인)합니다.
</details>

<br>

### 페이지 교체 알고리즘과 종류?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;`페이지 교체 알고리즘`은 다음 필요한 페이지가 메모리에 적재될 때 어떤 페이지를 스왑 아웃할지 기준이 되는 알고리즘입니다. 좋은 페이지 교체 알고리즘일 수록 페이지 폴트가 발생되는 빈도가 적어지기 때문에 페이지 교체 알고리즘의 핵심이 되는 것은 `페이지 폴트 횟수`와 이를 계산할 수 있는 `페이지 참조열(page reference string)`입니다.
  <br>
  &nbsp;&nbsp;첫 번째 페이지 교체 알고리즘은 `FIFO 페이지 교체 알고리즘`입니다. 가장 먼저 메모리에 할당된 페이지를 교체 대상으로 지정하는 알고리즘입니다. 자주 사용되는 페이지가 스왑 아웃 되었을 경우, 페이지 폴트가 빈번하게 발생한다는 단점이 있습니다.
  <br>
  &nbsp;&nbsp;다음은 `LRU(Least Recently Used) 페이지 교체 알고리즘`입니다. 이름 그대로 최근에 가장 적게 사용된 페이지를 교체하는 알고리즘으로 최근에 사용 빈도가 가장 적었던 페이지가 앞으로도 적게 사용될 것이라는 아이디어에 기반한 알고리즘입니다.
</details>

<br>

### 스레싱이란?

<details>
  <summary>펼쳐보기</summary>
  &nbsp;&nbsp;페이지 폴트 발생 빈도는 페이지 교체 알고리즘 이외에도 메모리의 물리적 한계로 인해 증가할 수 있습니다. 만약 메모리의 용량이 무한하다면 모든 프로세스의 페이지에 대해 프레임 할당을 할 수 있는 만큼 페이지 폴트가 발생하지 않을 것입니다. 이렇듯 메모리의 물리적 한계로 인해 프레임이 새 페이지로 교체되는 빈도가 빈번하게 발생하여 CPU 이용률이 저하되는 문제를 `스레싱(Thrashing)`이라고 부릅니다.
  <br>
  &nbsp;&nbsp;`스레싱`은 많은 프로세스가 메모리에 올라와 있을 때 발생합니다. 부족한 메모리 크기로 인해 페이지 폴트가 빈번하게 발생하고, 많은 페이지 교체가 이루어지는 동안 CPU 이용률은 저하되므로 더 많은 페이지를 메모리에 올리려는 시도가 일어나 악순환이 발생할 수 있습니다. 만약 스레싱이 해소되지 못하면 OS는 `Out of memory` 상태로 판단해 중요도가 낮은 프로세스를 강제로 종료합니다.
  <br>
  &nbsp;&nbsp;`스레싱`을 해소하기 위한 방법으로 `Working set` 알고리즘이 있습니다. 각 프로세스는 빈번하게 사용되는 페이지가 정해져 있는데, 그 페이지를 적재할 수 있을 만큼의 프레임이 비면 그때 메모리에 적재하는 기법입니다. `페이지 폴트 빈도(page-fault frequency)` 알고리즘은 페이지 폴트율에 대해 상한선과 하한선을 두고 범위 안에서만 프레임을 할당하는 방법입니다. 페이지 폴트율이 높으면 너무 적은 프레임이, 페이지 폴트율이 낮으면 너무 많은 프레임이 할당되었다는 아이디어에 기반하였습니다.
</details>